# -*- coding: utf-8 -*-
"""FinalProject-IDX.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wik4scgK_M5ytulQGg4uRo8zwirQAZtc

**Project-Based Internship**\
Nama : M. Arief Rahman Hakim\
ID/X Partner by Rekamin

# **Data Understanding – Prediksi Risiko Kredit**

## 1. Ringkasan Dataset

Dataset yang digunakan berisi informasi historis pinjaman dengan total **466.285 baris** dan **75 kolom**. Dataset ini mencakup informasi dari peminjam, jumlah dan kondisi pinjaman, status verifikasi, serta status akhir dari pinjaman tersebut.

### Struktur Dataset:
- **Jumlah Baris**: 466.285
- **Jumlah Kolom**: 75
- **Sumber**: IDX Partners: Loan Data 2007-2014
- **Tujuan**: Memprediksi **Good** or **Bad** dari pinjaman berdasarkan atribut awal saat pinjaman disetujui.

---

## 2. Pemahaman Kolom / Atribut

Berikut beberapa kolom yang penting dan sering digunakan dalam pemodelan risiko kredit:

| Nama Kolom          | Deskripsi                                       | Tipe Data     |
|---------------------|--------------------------------------------------|---------------|
| `loan_amnt`         | Jumlah pinjaman yang diajukan                    | Numerik       |
| `term`              | Durasi pinjaman (36 atau 60 bulan)               | Kategorikal   |
| `int_rate`          | Bunga pinjaman dalam persen                     | Numerik       |
| `installment`       | Cicilan bulanan                                 | Numerik       |
| `grade`, `sub_grade`| Kategori skor kredit internal                   | Kategorikal   |
| `emp_length`        | Lama bekerja peminjam                           | Kategorikal   |
| `home_ownership`    | Status kepemilikan rumah                        | Kategorikal   |
| `annual_inc`        | Pendapatan tahunan                              | Numerik       |
| `verification_status` | Status verifikasi pendapatan                 | Kategorikal   |
| `purpose`           | Tujuan pinjaman                                 | Kategorikal   |
| `dti`               | Debt-to-Income Ratio                            | Numerik       |
| `loan_status`       | Status akhir pinjaman (Target/Label)            | Kategorikal   |

Kolom `loan_status` akan digunakan sebagai **target prediksi**, yang dikategorikan menjadi:
- **Good**: Fully Paid, Current
- **Bad**: Charged off, Late, Default, dll

---

## 3. Eksplorasi Awal

Berikut adalah eksplorasi awal terhadap data:
"""

import pandas as pd

df = pd.read_csv("/content/loan_data_2007_2014.csv", low_memory=False)

print("Jumlah baris:", df.shape[0])
print("Jumlah kolom:", df.shape[1])

df.head()

df.describe()

df.describe(include='object')

df['loan_status'].value_counts(normalize=True) * 100

"""Hasil eksplorasi awal terhadap dataset menunjukkan beberapa pola umum:
- `loan_amnt`: bervariasi berkisar antara `$500` sampai `$35.000`.
- `int_rate`: berkisar antara 5.42% hingga 26.06%, dengan rata-rata sekitar 13.83%.
- `term`: hanya memiliki dua nilai, yaitu 36 months dan 60 months.
- `grade`: berkisar dari A (paling rendah risiko) hingga G (paling tinggi risiko).
- `annual_inc` : sangat bervariasi, dari $1.896 sampai $7.5 juta, menunjukkan ada outlier yang perlu dianalisis.
- `loan_status`: nilai yang paling sering muncul adalah Fully Paid dan Charged Off, yang akan diklasifikasikan sebagai risiko rendah dan tinggi dalam model.

Beberapa kolom memiliki nilai kosong (missing values) yang perlu diproses lebih lanjut:
- Beberapa kolom sepenuhnya kosong (466.285 missing), seperti: `all_util`, `inq_fi`, `total_cu_tl`, dll.
- Kolom lain memiliki sebagian missing, contoh: `emp_title` (sekitar 28.000 null), `annual_inc`, `last_pymnt_d`, dan `next_pymnt_d`.
- Penting untuk dilakukan: analisis lanjutan dan keputusan eliminasi atau imputasi.

# **Exploratory Data Analysis (EDA)**
"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/loan_data_2007_2014.csv')

sns.set(style='whitegrid')
plt.rcParams['figure.figsize'] = (12, 6)

"""## **Analisis Univariate**

### 1. Distribusi loan_amnt
"""

sns.histplot(df['loan_amnt'], kde=True, bins=40)
plt.title('Distribusi Jumlah Pinjaman (loan_amnt)')
plt.xlabel('Jumlah Pinjaman')
plt.ylabel('Frekuensi')
plt.show()

"""#### Hasil Analisis

Distribusi Jumlah Pinjaman (`loan_amnt`)
- Terdapat lonjakan signifikan pada nilai-nilai kelipatan tertentu seperti `$10.000`, `$15.000`, `$20.000`, dan `$35.000`.
- Ini menandakan adanya preferensi atau batasan jumlah pinjaman standar, kemungkinan berasal dari kebijakan lembaga pemberi pinjaman.
- Distribusi tidak simetris, agak mendekati distribusi multimodal.

### 2. Distribusi int_rate (bunga)
"""

sns.histplot(df['int_rate'], kde=True, bins=30, color='orange')
plt.title('Distribusi Bunga Pinjaman (int_rate)')
plt.xlabel('Bunga (%)')
plt.ylabel('Frekuensi')
plt.show()

"""#### Hasil Analisis

Distribusi Bunga (`int_rate`)
- Mayoritas bunga berkisar antara 10% hingga 18%, dengan puncak di sekitar 13–15%.
- Menariknya, bunga tinggi (>20%) cukup jarang, yang mungkin dikaitkan dengan risiko tinggi atau pengajuan dari profil borrower dengan credit score rendah.

### 3. Distribusi loan_status (target kandidat)
"""

sns.countplot(x='loan_status', data=df, order=df['loan_status'].value_counts().index)
plt.title('Distribusi Status Pinjaman')
plt.xlabel('Status')
plt.ylabel('Jumlah')
plt.xticks(rotation=45)
plt.show()

"""#### Hasil Analisis

Distribusi Status Pinjaman (`loan_status`)\
Mayoritas pinjaman berstatus:
- Current (~224K)

- Fully Paid (~185K)

Sementara status gagal bayar atau buruk meliputi:

- Charged Off (~43K)

- Late, Default, Grace Period, dan kategori khusus lainnya.

Artinya, dataset ini cukup imbalance, sehingga nanti perlu diperhatikan saat training model.

## **Analisis Bivariate – Perbandingan antar fitur**

### Perbandingan loan_amnt terhadap loan_status
"""

sns.boxplot(x='loan_status', y='loan_amnt', data=df)
plt.title('Jumlah Pinjaman vs Status Pinjaman')
plt.xticks(rotation=45)
plt.show()

"""#### Hasil Analisis

`loan_amnt` vs `loan_status`\
Secara umum, distribusi jumlah pinjaman mirip antar status, tapi ada indikasi:
- Status buruk (Charged Off, Default) cenderung memiliki median pinjaman sedikit lebih tinggi daripada yang Fully Paid.
- Pinjaman kecil juga bisa gagal bayar, artinya risiko tidak selalu tergantung jumlah pinjaman.

### Perbandingan interest rate terhadap loan_status
"""

sns.boxplot(x='loan_status', y='int_rate', data=df, palette='Set2')
plt.title('Bunga vs Status Pinjaman')
plt.xticks(rotation=45)
plt.show()

"""#### Hasil Analisis

`int_rate` vs `loan_status
- Ini pola menarik: semakin tinggi bunga (int_rate), semakin tinggi kemungkinan gagal bayar.

Contoh:

Rata-rata bunga untuk Charged Off dan Default lebih tinggi dibanding Fully Paid.

- Logis, karena peminjam berisiko tinggi biasanya dikenakan bunga lebih besar → ini bisa jadi fitur kuat dalam model prediksi.

## **Korelasi Antar Fitur Numerik**

### Korelasi matriks hanya dengan kolom numerik
"""

corr_matrix = df.corr(numeric_only=True)
plt.figure(figsize=(15, 12))
sns.heatmap(corr_matrix, cmap='coolwarm', annot=False)
plt.title('Heatmap Korelasi Antar Fitur Numerik')
plt.show()

"""#### Hasil Analisis

Heatmap Korelasi Antar Fitur Numerik
- Korelasi kuat terlihat antara:

    loan_amnt, funded_amnt, funded_amnt_inv, dan installment → fitur ini sangat saling terkait.

    total_pymnt, total_rec_prncp, dan out_prncp → berhubungan dengan jumlah pembayaran.

- Sebagian besar fitur lainnya punya korelasi rendah, yang bisa bagus untuk keunikan masing-masing fitur saat dimasukkan ke model.

### Kesimpulan EDA

Insight dari EDA
- Fitur int_rate, loan_amnt, dan beberapa variabel keuangan sangat menjanjikan untuk prediksi risiko.

- Variabel loan_status perlu disederhanakan (misalnya: “baik” vs “buruk”) karena sangat beragam → penting untuk preprocessing.

- Dataset tidak seimbang antara pinjaman lancar dan gagal → bisa jadi masalah saat modelling (perlu penanganan seperti resampling).

- Beberapa fitur redundan atau sangat berkorelasi, perlu dipertimbangkan untuk dieliminasi agar menghindari multikolinearitas.

# **Data Preparation**
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/loan_data_2007_2014.csv',low_memory=False)

# Menghapus Kolom dengan Kardinalitas tinggi
high_card_cols = ['emp_title', 'title', 'desc', 'url', 'zip_code', 'member_id', 'id']
df = df.drop(columns=[col for col in high_card_cols if col in df.columns], errors='ignore')

# Menghapus kolom yang memiliki missing value > 60%
missing_thresh = 0.6
df = df.loc[:, df.isnull().mean() < missing_thresh]

# Melakukan imputasi terhadap missing value, jika numerik gunakan median dan jika katagorikal gunakan modus
for col in df.select_dtypes(include='number').columns:
    df[col].fillna(df[col].median(), inplace=True)

for col in df.select_dtypes(include='object').columns:
    df[col].fillna(df[col].mode()[0], inplace=True)

# Encode `loan_status` jadi binary target
def simplify_status(status):
    return 1 if status not in ['Fully Paid', 'Current'] else 0

df['loan_status'] = df['loan_status'].apply(simplify_status)

# Encode fitur kategorikal yang penting dan low-cardinality
label_cols = ['term', 'grade', 'sub_grade', 'home_ownership',
              'verification_status', 'purpose', 'application_type']

for col in label_cols:
    if col in df.columns:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])

# Hapus kolom kategorikal lain yang belum diproses
drop_obj = df.select_dtypes(include='object').columns
df.drop(columns=drop_obj, inplace=True)

# Scaling
features = df.drop('loan_status', axis=1)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(features)
X = pd.DataFrame(X_scaled, columns=features.columns)
y = df['loan_status']

# Simpan data akhir
df_final = pd.concat([X, y], axis=1)
df_final.to_csv('/content/preprocessed_loan_data.csv', index=False)
print(" Data berhasil disimpan sebagai preprocessed_loan_data.csv")

# Split train-test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
print("Train shape:", X_train.shape)
print("Test shape :", X_test.shape)

# Visualisasi distribusi fitur setelah imputasi
plt.figure(figsize=(12, 6))
df_imputed = df.copy()
numeric_cols = df_imputed.select_dtypes(include='number').columns
df_imputed[numeric_cols].hist(bins=30, figsize=(12, 8), edgecolor='black')
plt.suptitle("Distribusi Fitur Numerik Setelah Imputasi", fontsize=16)
plt.show()

# Visualisasi boxplot untuk menunjukkan fitur setelah scaling
plt.figure(figsize=(12, 6))
sns.boxplot(data=X_scaled, orient="h", palette="Set2")
plt.title("Boxplot Fitur Setelah Scaling", fontsize=16)
plt.xlabel("Nilai Fitur (Setelah Scaling)")
plt.show()

"""# **Membangun Model**

## Logistic Reggression

### Eksperimen 1
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix, roc_curve
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt
import seaborn as sns

# Inisialisasi dan training model
logreg = LogisticRegression(max_iter=1000, random_state=42)
logreg.fit(X_train, y_train)

# Prediksi
y_pred_train = logreg.predict(X_train)
y_pred_test = logreg.predict(X_test)

# Evaluasi on test set
print("=== Evaluation on Test Set ===")
print("Accuracy :", accuracy_score(y_test, y_pred_test))
print("Precision:", precision_score(y_test, y_pred_test))
print("Recall   :", recall_score(y_test, y_pred_test))
print("F1 Score :", f1_score(y_test, y_pred_test))
print("ROC AUC  :", roc_auc_score(y_test, logreg.predict_proba(X_test)[:, 1]))
print("\nClassification Report:\n", classification_report(y_test, y_pred_test))

# Confusion matrix
conf_matrix = confusion_matrix(y_test, y_pred_test)
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["Baik", "Buruk"], yticklabels=["Baik", "Buruk"])
plt.title("Confusion Matrix - Test Set")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ROC - Cruve
fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:, 1])
plt.plot(fpr, tpr, label='Logistic Regression')
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

cv_scores = cross_val_score(logreg, X_train, y_train, cv=5, scoring='roc_auc')
print("Cross-Validation ROC-AUC Scores:", cv_scores)
print("Average CV ROC-AUC:", cv_scores.mean())

print("Train Accuracy :", accuracy_score(y_train, y_pred_train))
print("Test Accuracy  :", accuracy_score(y_test, y_pred_test))

"""### Eksperimen 2"""

from sklearn.metrics import precision_recall_curve
logreg = LogisticRegression(max_iter=1000, random_state=42)
logreg.fit(X_train, y_train)

y_probs = logreg.predict_proba(X_test)[:, 1]

# Brute Force tresholds
thresholds = np.arange(0.1, 0.9, 0.05)
results = []

for t in thresholds:
    y_pred_thresh = (y_probs >= t).astype(int)
    precision = precision_score(y_test, y_pred_thresh)
    recall = recall_score(y_test, y_pred_thresh)
    f1 = f1_score(y_test, y_pred_thresh)
    results.append((t, precision, recall, f1))

results_df = pd.DataFrame(results, columns=['Threshold', 'Precision', 'Recall', 'F1 Score'])
print(results_df)

# Visualisasi
plt.plot(results_df['Threshold'], results_df['Recall'], label='Recall', marker='o')
plt.plot(results_df['Threshold'], results_df['Precision'], label='Precision', marker='s')
plt.plot(results_df['Threshold'], results_df['F1 Score'], label='F1 Score', marker='^')
plt.xlabel('Threshold')
plt.ylabel('Score')
plt.title('Tuning Threshold: Precision vs Recall vs F1')
plt.legend()
plt.grid(True)
plt.show()

optimal_threshold = 0.20

y_pred_new = (y_probs >= optimal_threshold).astype(int)

from sklearn.metrics import classification_report, confusion_matrix

print("== Evaluasi dengan Threshold =", optimal_threshold, "==")
print("Classification Report:\n", classification_report(y_test, y_pred_new))

# Confusion matrix baru
sns.heatmap(confusion_matrix(y_test, y_pred_new), annot=True, fmt="d", cmap="Blues", xticklabels=["Baik", "Buruk"], yticklabels=["Baik", "Buruk"])
plt.title("Confusion Matrix dengan Threshold Baru")
plt.xlabel("Prediksi")
plt.ylabel("Aktual")
plt.show()

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

y_prob = logreg.predict_proba(X_test)[:, 1]

optimal_threshold = 0.20
y_pred_new = (y_prob >= optimal_threshold).astype(int)

fpr, tpr, thresholds = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)

# Plot ROC Curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='b', label=f'ROC curve (threshold = {optimal_threshold}, AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()

"""#### Hasil Logistic Reggression

**Data Modelling – Logistic Regression**
#### 1. **Pemilihan Model**

Model yang digunakan dalam tahap awal pengembangan sistem prediksi risiko kredit adalah Logistic Regression. Pemilihan model ini didasarkan pada karakteristik masalah klasifikasi biner (baik vs. buruk) serta kemampuannya yang baik sebagai baseline model karena:

  - Cepat dalam proses pelatihan,
  - Dapat diinterpretasi,
  - Tidak terlalu kompleks namun cukup akurat untuk skenario awal.

  Target variabel (loan_status) disederhanakan menjadi dua kelas:

  - 0: pinjaman baik (Fully Paid atau Current),
  - 1: pinjaman berisiko/gagal (selain itu, seperti Charged Off, Default, Late, dsb).

#### 2. **Pelatihan Model**

Model dilatih menggunakan dataset hasil preprocessing yang terdiri dari:

  - Fitur numerik yang telah diskalakan menggunakan StandardScaler,

  - Fitur kategorikal yang telah diencode menggunakan LabelEncoder,

  - Split data dilakukan dengan rasio 80:20 antara train dan test, menggunakan stratified sampling agar proporsi kelas tetap seimbang.

  Model Logistic Regression dilatih menggunakan parameter default, dengan batas iterasi sebesar 1000.

#### 3. **Evaluasi Awal (Threshold Default 0.5)**

Hasil evaluasi model pada threshold default (0.5) ditunjukkan sebagai berikut:


| Metrik           | Nilai   |
|------------------|---------|
| Accuracy         | 96.77%  |
| Precision        | 98.69%  |
| Recall           | 74.74%  |
| F1 Score         | 85.06%  |
| ROC AUC Score    | 95.17%  |

Model menunjukkan akurasi dan precision yang sangat tinggi, namun nilai recall relatif lebih rendah, yang menunjukkan bahwa model masih melewatkan beberapa kasus gagal bayar (false negative).

#### 4. **Tuning Threshold untuk Optimasi Recall**

Untuk meningkatkan kemampuan model dalam mendeteksi pinjaman gagal bayar, dilakukan penyesuaian threshold prediksi probabilitas. Threshold diturunkan dari 0.5 ke 0.2, dengan hasil evaluasi sebagai berikut:


| Metrik           | Nilai   |
|------------------|---------|
| Accuracy         | 96.68%  |
| Precision        | 92.41%  |
| Recall           | 78.27%  |
| F1 Score         | 84.76%  |
| ROC AUC Score    | ~95.17% |

Hasil ini menunjukkan peningkatan signifikan pada recall, dengan sedikit penurunan precision dan akurasi yang masih dalam batas sangat baik.

#### 5. **Confusion Matrix Threshold 0.20**

Model berhasil mengklasifikasikan lebih banyak kasus buruk dengan threshold yang diturunkan, sehingga menjadi lebih sensitif terhadap risiko kredit, tanpa banyak mengorbankan performa umum model.

|                   | Prediksi Baik | Prediksi Buruk |
|-------------------|---------------|----------------|
| Aktual Baik (0)   | 81.056        | 737            |
| Aktual Buruk (1)  | 2.490         | 8.974          |


#### **Kesimpulan**

- Model dengan threshold default (0.5) lebih baik dalam mendeteksi pinjaman yang baik tanpa melewatkan banyak data, menghasilkan recall 1.00, F1 Score 0.98, dan akurasi yang lebih tinggi.

- Model dengan threshold 0.20 lebih konservatif dalam mengklasifikasikan pinjaman sebagai baik. Ini meningkatkan precision (karena lebih hati-hati dalam memberi label baik), tetapi recall menurun, yang berarti beberapa pinjaman baik terlewatkan.

#### **Rekomendasi**

- Jika tujuan utama adalah meminimalkan kesalahan dalam mendeteksi pinjaman baik, threshold default (0.5) lebih baik karena memberikan recall yang lebih tinggi.

- Jika model perlu lebih selektif dalam mendeteksi pinjaman baik (menghindari false positives), threshold 0.20 mungkin lebih cocok meskipun ada penurunan recall.

## Random Forest

### Eksperimen 1
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix, roc_curve, auc
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import seaborn as sns
import matplotlib.pyplot as plt

# Inisialisasi dan training
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# Prediksi
y_pred_rf = rf.predict(X_test)
y_prob_rf = rf.predict_proba(X_test)[:, 1]

# Evaluasi
print("=== Random Forest Evaluation ===")
print("Accuracy :", accuracy_score(y_test, y_pred_rf))
print("Precision:", precision_score(y_test, y_pred_rf))
print("Recall   :", recall_score(y_test, y_pred_rf))
print("F1 Score :", f1_score(y_test, y_pred_rf))
print("ROC AUC  :", roc_auc_score(y_test, y_prob_rf))
print("\nClassification Report:\n", classification_report(y_test, y_pred_rf))

# Confusion Matrix
sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt="d", cmap="Greens", xticklabels=["Baik", "Buruk"], yticklabels=["Baik", "Buruk"])
plt.title("Confusion Matrix - Random Forest")
plt.xlabel("Prediksi")
plt.ylabel("Aktual")
plt.show()

# Feature Importance
importances = rf.feature_importances_
feat_names = X_train.columns
feature_df = pd.DataFrame({'Fitur': feat_names, 'Importance': importances})
top_features = feature_df.sort_values(by='Importance', ascending=False).head(15)

# Plot ROC Curve
fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test, y_prob_rf)
roc_auc_rf = auc(fpr_rf, tpr_rf)
plt.figure(figsize=(8, 6))
plt.plot(fpr_rf, tpr_rf, color='b')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Random Forest')
plt.show()

plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Fitur', data=top_features)
plt.title('Top 15 Fitur Terpenting - Random Forest')
plt.tight_layout()
plt.show()

"""### Eksperimen 2"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix, roc_curve
from sklearn.metrics import classification_report, roc_auc_score
import time

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 3],
    'max_features': ['sqrt', 'log2']
}

# Inisialisasi
rf_base = RandomForestClassifier(random_state=42, n_jobs=-1)

grid_search = GridSearchCV(estimator=rf_base, param_grid=param_grid,
                           scoring='roc_auc', cv=3, verbose=2, n_jobs=-1)

start = time.time()
grid_search.fit(X_train, y_train)
end = time.time()
print(f"Waktu Grid Search: {round(end - start, 2)} detik")

print("\n Best Params:", grid_search.best_params_)
print(" Best ROC-AUC Score (CV):", grid_search.best_score_)

best_rf = grid_search.best_estimator_
y_pred_best = best_rf.predict(X_test)
y_prob_best = best_rf.predict_proba(X_test)[:, 1]

print("\n=== Evaluasi di Test Set (Model Terbaik) ===")
print("Accuracy :", accuracy_score(y_test, y_pred_best))
print("Precision:", precision_score(y_test, y_pred_best))
print("Recall   :", recall_score(y_test, y_pred_best))
print("F1 Score :", f1_score(y_test, y_pred_best))
print("ROC AUC  :", roc_auc_score(y_test, y_prob_best))
print("\nClassification Report:\n", classification_report(y_test, y_pred_best))

"""### Eksperimen 3"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix, roc_curve
from sklearn.metrics import classification_report, roc_auc_score
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import time

# Parameter grid
param_dist = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 3],
    'max_features': ['sqrt', 'log2']
}

# Inisialisasi RandomForest dan RandomizedSearch
rf_base = RandomForestClassifier(random_state=42, n_jobs=-1)
random_search = RandomizedSearchCV(estimator=rf_base, param_distributions=param_dist,
                                   n_iter=10, scoring='roc_auc', cv=3, verbose=2, n_jobs=-1)

# Fit RandomizedSearchCV
start = time.time()
random_search.fit(X_train, y_train)
end = time.time()

# Hasil terbaik
print(f"Waktu RandomizedSearch: {round(end - start, 2)} detik")
print("\nBest Params:", random_search.best_params_)
print("Best ROC-AUC Score (CV):", random_search.best_score_)

# Evaluasi model terbaik
best_rf = random_search.best_estimator_
y_pred_best = best_rf.predict(X_test)
y_prob_best = best_rf.predict_proba(X_test)[:, 1]

print("\n=== Evaluasi di Test Set (Model Terbaik) ===")
print("Accuracy :", accuracy_score(y_test, y_pred_best))
print("Precision:", precision_score(y_test, y_pred_best))
print("Recall   :", recall_score(y_test, y_pred_best))
print("F1 Score :", f1_score(y_test, y_pred_best))
print("ROC AUC  :", roc_auc_score(y_test, y_prob_best))

# Confusion Matrix
conf_matrix = confusion_matrix(y_test, y_pred_best)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", xticklabels=["Baik", "Buruk"], yticklabels=["Baik", "Buruk"])
plt.title("Confusion Matrix - Random Forest (Model Terbaik)")
plt.xlabel("Prediksi")
plt.ylabel("Aktual")
plt.show()

# ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, y_prob_best)
roc_auc = auc(fpr, tpr)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='b', label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve - Random Forest')
plt.legend(loc="lower right")
plt.show()

"""#### Hasil Random Forest

**Data Modelling – Random Forest**
#### 1. **Pemilihan Model**

Dalam tahap Data Modelling ini, kita mengembangkan model Random Forest untuk memprediksi risiko kredit berdasarkan dataset yang telah diproses. Random Forest adalah model ensemble yang terdiri dari banyak pohon keputusan, yang memberikan akurasi tinggi dan tahan terhadap overfitting.

Saya melakukan dua eksperimen untuk membandingkan performa:

- Random Forest (Default): Model ini menggunakan parameter default dari RandomForestClassifier tanpa penyesuaian hyperparameter.

- Random Forest dengan RandomizedSearchCV: Hyperparameter tuning dilakukan menggunakan RandomizedSearchCV untuk mengoptimalkan parameter model dan meningkatkan performa.


#### 2. **Random Forest (Default)**

Pada eksperimen pertama, model Random Forest dilatih menggunakan parameter default.

##### Hasil Evaluasi:

| Metrik           | Nilai   |
|------------------|---------|
| Accuracy         | 97.58%  |
| Precision        | 99.36%  |
| Recall           | 80.87%  |
| F1 Score         | 89.16%  |
| ROC AUC Score    | 98.15%  |

- **Accuracy** sangat tinggi, menunjukkan bahwa sebagian besar prediksi model tepat.
- **Precision** sangat baik (99.36%), namun recall (80.87%) menunjukkan bahwa ada beberapa false negative (pinjaman berisiko yang tidak terdeteksi).
- **ROC AUC** adalah 98.15%, menunjukkan bahwa model mampu membedakan dengan baik antara pinjaman baik dan buruk.

##### Confusion Matrix (Default):

|                   | Prediksi Baik | Prediksi Buruk |
|-------------------|---------------|----------------|
| Aktual Baik (0)   | 81.733        | 60             |
| Aktual Buruk (1)  | 2.193         | 9.271          |

#### 3. **Random Forest dengan RandomizedSearchCV**

Pada eksperimen kedua, saya melakukan tuning hyperparameter menggunakan **RandomizedSearchCV** untuk mencari parameter terbaik.

##### Hasil Evaluasi:

| Metrik           | Nilai   |
|------------------|---------|
| Accuracy         | 97.50%  |
| Precision        | 99.42%  |
| Recall           | 80.14%  |
| F1 Score         | 88.75%  |
| ROC AUC Score    | 98.33%  |

- **Accuracy** hampir identik dengan model default, tetapi recall sedikit menurun ke 80.14%, menunjukkan bahwa model lebih baik dalam mendeteksi pinjaman yang berisiko gagal bayar.
- **Precision** tetap sangat tinggi (99.42%).
- **ROC AUC** meningkat menjadi 98.33%, menunjukkan kemampuan model yang lebih baik dalam memisahkan kelas baik dan buruk.

##### Confusion Matrix (RandomizedSearchCV)

|                   | Prediksi Baik | Prediksi Buruk |
|-------------------|---------------|----------------|
| Aktual Baik (0)   | 81.740        | 53             |
| Aktual Buruk (1)  | 2.276         | 9.188          |

#### 4. **Perbandingan Model**

| Model                                | Accuracy | Precision | Recall  | F1 Score | ROC AUC |
|--------------------------------------|----------|-----------|---------|----------|---------|
| Random Forest (Default)              | 97.58%   | 99.36%    | 80.87%  | 89.17%   | 98.15%  |
| Random Forest (RandomizedSearchCV)   | 97.50%   | 99.42%    | 80.14%  | 88.75%   | 98.33%  |

##### Poin-poin Kunci:
- **Akurasi** dan **Precision**: Kedua model hampir identik dalam hal akurasi dan precision, dengan sedikit perbedaan antara model default dan RandomizedSearchCV.
- **Recall**: Model dengan RandomizedSearchCV memberikan sedikit penurunan recall (80.14%) dibandingkan model default (80.87%).
- **ROC AUC**: RandomizedSearchCV memberikan peningkatan kecil dalam ROC AUC (98.27% vs 98.15%).

#### **Kesimpulan**
- Random Forest (Default) memiliki sedikit keunggulan dalam accuracy, recall, dan F1 score. Ini menunjukkan bahwa model default sedikit lebih baik dalam mendeteksi pinjaman berisiko dan menghindari false negatives.

- Random Forest (RandomizedSearchCV) memiliki sedikit keunggulan dalam precision dan ROC AUC. Ini menunjukkan bahwa model RandomizedSearchCV lebih baik dalam menghindari false positives dan lebih baik dalam membedakan antara dua kelas.

### **Rekomendasi**

Jika keseimbangan antara precision dan recall lebih penting, model Default mungkin lebih baik. Namun, jika kamu lebih mengutamakan kemampuan model dalam membedakan kedua kelas dengan lebih baik (ROC AUC), maka RandomizedSearchCV bisa menjadi pilihan yang lebih tepat.

## XGBoost

### Eksperimen 1
"""

import xgboost as xgb
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, auc, accuracy_score, precision_score, recall_score, f1_score, roc_curve
import seaborn as sns
import matplotlib.pyplot as plt
import time

# Inisialisasi model XGBoost
xgb_model = xgb.XGBClassifier(random_state=42, n_jobs=-1, use_label_encoder=False)

# grid parameter untuk pencarian hyperparameter
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [3, 5, 10],
    'learning_rate': [0.01, 0.05, 0.1],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0],
}

# GridSearchCV untuk pencarian parameter terbaik
grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='roc_auc', cv=3, verbose=2, n_jobs=-1)

# Fit model
start = time.time()
grid_search.fit(X_train, y_train)
end = time.time()
print(f"⏱️ Waktu Grid Search: {round(end - start, 2)} detik")

#Hasil terbaik
print("\n Best Params:", grid_search.best_params_)
print(" Best ROC-AUC Score (CV):", grid_search.best_score_)

# Evaluasi model terbaik
best_xgb = grid_search.best_estimator_
y_pred_best = best_xgb.predict(X_test)
y_prob_best = best_xgb.predict_proba(X_test)[:, 1]

print("\n=== Evaluasi di Test Set (Model Terbaik) ===")
print("Accuracy :", accuracy_score(y_test, y_pred_best))
print("Precision:", precision_score(y_test, y_pred_best))
print("Recall   :", recall_score(y_test, y_pred_best))
print("F1 Score :", f1_score(y_test, y_pred_best))
print("ROC AUC  :", roc_auc_score(y_test, y_prob_best))
print("\nClassification Report:\n", classification_report(y_test, y_pred_best))

# Confusion matrix
cm = confusion_matrix(y_test, y_pred_best)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Baik", "Buruk"], yticklabels=["Baik", "Buruk"])
plt.title('Confusion Matrix - XGBoost')
plt.xlabel('Prediksi')
plt.ylabel('Aktual')
plt.show()

# ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, y_prob_best)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='b', label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve - XGBoost')
plt.legend(loc="lower right")
plt.show()

"""#### Hasil XGboost

Data Modelling – XGBoost
#### 1. **Pemilihan Model**
Model XGBoost menggunakan parameter default untuk mengklasifikasikan risiko kredit dalam dataset yang diberikan. Model ini dilatih menggunakan XGBoostClassifier yang sudah di-tune menggunakan parameter default dan dilatih menggunakan training set yang telah disiapkan.

#### 2. **Metrik Evaluasi Model pada Test Set**

| Metrik       | Nilai   |
|--------------|---------|
| Accuracy     | 98.54%  |
| Precision    | 99.66%  |
| Recall       | 88.39%  |
| F1 Score     | 93.69%  |
| ROC AUC      | 99.31%  |

#### 3. **Confusion Matrix**

Confusion Matrix pada test set menunjukkan perbandingan antara nilai aktual dan prediksi dari model. Berikut adalah matrix untuk model XGBoost (Default Parameters):

|                   | Prediksi Baik | Prediksi Buruk |
|-------------------|---------------|----------------|
| Aktual Baik (0)   | 81.758        | 35             |
| Aktual Buruk (1)  | 1.331         | 10.133         |

##### **Interpretasi**
- **True Positives (Baik)**: 81.758 pinjaman benar-benar baik yang diprediksi sebagai baik.
- **False Negatives (Buruk)**: 1.331 pinjaman yang sebenarnya buruk, tetapi diprediksi sebagai baik.
- **False Positives (Baik)**: 35 pinjaman yang sebenarnya baik tetapi diprediksi sebagai buruk.
- **True Negatives (Buruk)**: 10.133 pinjaman benar-benar buruk yang diprediksi sebagai buruk.

#### 4. **ROC Curve**
Model XGBoost dengan parameter default menghasilkan ROC Curve yang sangat baik, menunjukkan kemampuan model dalam membedakan antara pinjaman baik dan buruk. AUC (Area Under Curve) untuk model ini adalah 99.31%, yang menandakan model memiliki kemampuan sebaik atau lebih baik dalam memisahkan dua kelas, yaitu baik dan buruk.

#### 5. **Evaluasi Berdasarkan Kinerja Metrik**
- Accuracy: Model ini mencapai 98.54% akurasi, yang berarti model dapat memprediksi dengan benar sekitar 98,5% dari seluruh data test.
- Precision: Dengan 99.66%, model ini memiliki precision yang sangat baik dalam mengidentifikasi pinjaman yang baik.
- Recall: Model ini memiliki recall 88.39%, yang menunjukkan bahwa model dapat mendeteksi 88,39% pinjaman buruk dengan benar.
- F1 Score: Model memiliki F1 Score 93.69%, yang menunjukkan keseimbangan yang sangat baik antara precision dan recall.
- ROC AUC: Dengan AUC 99.31%, model memiliki kemampuan superior dalam memisahkan kelas baik dan buruk.

#### **Kesimpulan**
Model XGBoost dengan parameter default menunjukkan kinerja yang sangat baik dalam mengklasifikasikan pinjaman dengan risiko kredit. Meskipun terdapat sedikit false negatives, model ini dapat mengklasifikasikan pinjaman dengan sangat baik dalam hal precision, recall, dan ROC AUC. AUC yang tinggi menandakan bahwa model sangat efisien dalam membedakan antara dua kelas, dengan recall yang lebih rendah menunjukkan bahwa model ini sedikit lebih cenderung untuk memprediksi pinjaman yang baik daripada buruk (menghindari false positives).

# **KESIMPULAN**

## Tabel Perbandingan Metrik Evaluasi untuk Setiap Model:

| Model                        | Accuracy | Precision | Recall  | F1 Score | ROC AUC |
|------------------------------|----------|-----------|---------|----------|---------|
| Logistic Regression           | 96.77%   | 98.69%    | 74.75%  | 85.06%   | 95.17%  |
| Random Forest (Default)       | 97.58%   | 99.36%    | 80.87%  | 89.17%   | 98.15%  |
| Random Forest (RandomizedSearch) | 97.50%   | 99.42%    | 80.14%  | 88.75%   | 98.33%  |
| XGBoost (Default)             | 98.54%   | 99.66%    | 88.39%  | 93.69%   | 99.31%  |

---

## Kesimpulan

- **Model Terbaik**: Berdasarkan AUC dan F1 Score, **XGBoost** dengan parameter default menunjukkan performa terbaik.
- **Random Forest (Default)** memberikan keseimbangan yang sangat baik antara **Precision** dan **Recall**, menjadikannya model yang sangat baik jika lebih mengutamakan deteksi risiko kredit.
- **Logistic Regression** memberikan hasil yang stabil, tetapi model ini sedikit kurang baik dibandingkan dengan **Random Forest** dan **XGBoost** dalam hal **recall** dan **AUC**.

## Rekomendasi:
Model **XGBoost** dapat digunakan untuk aplikasi prediksi risiko kredit jika fokus pada kemampuan membedakan kelas dengan **AUC** tinggi dan **recall** yang baik.
"""